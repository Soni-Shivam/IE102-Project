{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3J8brHTsknF"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "folder_path = kagglehub.dataset_download(\"rohanrao/formula-1-world-championship-1950-2020\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdAy3oHiSll-",
        "outputId": "9c6aac29-52a3-4934-de39-cc42a8d1939b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Final features exported successfully to 'f1_final_features.csv'\n"
          ]
        }
      ],
      "source": [
        "# final project execution starts here\n",
        "import pandas as pd\n",
        "\n",
        "# Load the relevant CSVs from the Kaggle dataset\n",
        "# These files should be placed in the current directory or the path should be adjusted\n",
        "results = pd.read_csv(folder_path + \"/\" +\"results.csv\")\n",
        "races = pd.read_csv(folder_path + \"/\" +\"races.csv\")\n",
        "qualifying = pd.read_csv(folder_path + \"/\" +\"qualifying.csv\")\n",
        "pit_stops = pd.read_csv(folder_path + \"/\" +\"pit_stops.csv\")\n",
        "constructor_standings = pd.read_csv(folder_path + \"/\" +\"constructor_standings.csv\")\n",
        "constructors = pd.read_csv(folder_path + \"/\" +\"constructors.csv\")\n",
        "drivers = pd.read_csv(folder_path + \"/\" +\"drivers.csv\")\n",
        "status = pd.read_csv(folder_path + \"/\" +\"status.csv\")\n",
        "\n",
        "#races = races[(races['year'] >= 2011) & (races['year'] <= 2018)]\n",
        "\n",
        "# Step 1: Get latest constructor standings per constructorId and raceId\n",
        "# You might want to use the max 'points' or latest 'position'\n",
        "constructor_standings_latest = constructor_standings.sort_values(by=['raceId', 'points'], ascending=[True, False])\n",
        "constructor_standings_latest = constructor_standings_latest.drop_duplicates(subset=['raceId', 'constructorId'])\n",
        "\n",
        "# Step 2: Merge constructor name into standings (not into results yet)\n",
        "constructor_standings_latest = constructor_standings_latest.merge(\n",
        "    constructors[['constructorId', 'name']], on='constructorId', how='left'\n",
        ").rename(columns={'name': 'constructor_name'})\n",
        "\n",
        "# Step 3: Make sure results already has constructorId, not constructor_name\n",
        "# (we'll map constructorId → name again for consistency)\n",
        "results = results.merge(\n",
        "    constructors[['constructorId', 'name']], on='constructorId', how='left'\n",
        ").rename(columns={'name': 'constructor_name'})\n",
        "\n",
        "# Step 4: Now safely merge constructor standings using constructorId + raceId\n",
        "results = results.merge(\n",
        "    constructor_standings_latest[['raceId', 'constructorId', 'points']],\n",
        "    on=['raceId', 'constructorId'], how='left'\n",
        ").rename(columns={'points': 'constructor_standing_points'})\n",
        "\n",
        "\n",
        "# results = results.merge(constructors[['constructorId', 'name']], on='constructorId', how='left')\n",
        "# results.rename(columns={'name': 'constructor_name'}, inplace=True)\n",
        "\n",
        "# Merge to get race details (including year, round, weather proxy info can be derived from race name or date later)\n",
        "results = results.merge(races[['raceId', 'year', 'round', 'name', 'date', 'circuitId']], on='raceId', how='left')\n",
        "\n",
        "# # Merge qualifying data to get grid position\n",
        "# results = results.merge(qualifying[['raceId', 'driverId', 'position']], on=['raceId', 'driverId'], how='left')\n",
        "# results.rename(columns={'position': 'qualifying_position'}, inplace=True)\n",
        "\n",
        "# 1. Pit stop time (total pit stop duration per driver per race)\n",
        "# fixing pit stop being a str\n",
        "pit_stops['duration'] = pd.to_numeric(pit_stops['duration'], errors='coerce')\n",
        "pit_stop_time = pit_stops.groupby(['raceId', 'driverId'])['duration'].sum().reset_index()\n",
        "pit_stop_time = pit_stop_time.rename(columns={'duration': 'total_pit_stop_time'})\n",
        "\n",
        "# 2. Constructor standing\n",
        "constructor_standings = constructor_standings.merge(constructors[['constructorId', 'name']], on='constructorId', how='left')\n",
        "constructor_standings.rename(columns={'name': 'constructor_name'}, inplace=True)\n",
        "results = results.merge(constructor_standings[['raceId', 'constructor_name', 'points']],\n",
        "                        on=['raceId', 'constructor_name'], how='left')\n",
        "results.rename(columns={'points_y': 'constructor_standing_points'}, inplace=True)\n",
        "\n",
        "# 3. Grid = current skill (already in qualifying_position)\n",
        "\n",
        "# 4. Absolute skill = average points per driver till that race\n",
        "# First sort by date to ensure cumulative stats make sense\n",
        "results = results.sort_values(by=['driverId', 'year', 'round'])\n",
        "results['cumulative_points'] = results.groupby('driverId')['points_x'].cumsum() - results['points_x']\n",
        "results['races_so_far'] = results.groupby('driverId').cumcount()\n",
        "results['avg_driver_points'] = results['cumulative_points'] / results['races_so_far'].replace(0, 1)  # avoid divide by 0\n",
        "\n",
        "# 5. Weather proxy: extract from race name or date (to be done externally or from `raceId` + location)\n",
        "# For now, we can add a placeholder or leave for manual mapping later.\n",
        "\n",
        "# 6. Avg pit stop rate per circuit (track difficulty proxy)\n",
        "avg_pit_rate = pit_stops.groupby('raceId')['stop'].nunique().reset_index()\n",
        "avg_pit_rate = avg_pit_rate.merge(races[['raceId', 'circuitId']], on='raceId', how='left')\n",
        "track_pit_rate = avg_pit_rate.groupby('circuitId')['stop'].mean().reset_index()\n",
        "track_pit_rate.rename(columns={'stop': 'avg_pit_stops_per_race'}, inplace=True)\n",
        "\n",
        "# 7. DNF rate = percent of drivers who did not finish (position is null or status not 'Finished')\n",
        "results = results.merge(status, on='statusId', how='left')  # adds 'status' column\n",
        "dnf_data = results.copy()\n",
        "dnf_data['dnf'] = dnf_data['status'].apply(lambda x: 1 if x != 'Finished' else 0)\n",
        "dnf_rate = dnf_data.groupby('circuitId')['dnf'].mean().reset_index()\n",
        "dnf_rate.rename(columns={'dnf': 'avg_dnf_rate'}, inplace=True)\n",
        "\n",
        "# Final merge to assemble features\n",
        "features = results.merge(pit_stop_time, on=['raceId', 'driverId'], how='left')\n",
        "features = features.merge(track_pit_rate, on='circuitId', how='left')\n",
        "features = features.merge(dnf_rate, on='circuitId', how='left')\n",
        "\n",
        "# # bug fixes\n",
        "# # Just in case, remove any duplicates\n",
        "# qualifying_cleaned = qualifying[['raceId', 'driverId', 'position']].dropna()\n",
        "\n",
        "# # Rename 'position' to something clearer\n",
        "# qualifying_cleaned = qualifying_cleaned.rename(columns={'position': 'qualifying_position'})\n",
        "\n",
        "# # Merge into main feature set\n",
        "# features = features.merge(qualifying_cleaned, on=['raceId', 'driverId'], how='left')\n",
        "\n",
        "#now use grid pos instead of qualifying pos\n",
        "# Assuming results is already loaded\n",
        "grid_data = results[['raceId', 'driverId', 'grid']]\n",
        "features = features.merge(grid_data, on=['raceId', 'driverId'], how='left')\n",
        "features['grid'] = results['grid']\n",
        "\n",
        "\n",
        "\n",
        "# Select final columns\n",
        "final_features = features[[\n",
        "    'raceId', 'driverId', 'constructorId', 'points_x',  # target\n",
        "    'total_pit_stop_time',\n",
        "    'constructor_standing_points',\n",
        "    'grid',\n",
        "    'avg_driver_points',\n",
        "    'avg_pit_stops_per_race',\n",
        "    'avg_dnf_rate'\n",
        "]].dropna()\n",
        "\n",
        "final_features.rename(columns={'points_x': 'target_points'}, inplace=True)\n",
        "final_features.head()\n",
        "\n",
        "# Export the final features to a CSV file\n",
        "final_features.to_csv(\"f1_final_features.csv\", index=False)\n",
        "\n",
        "print(\"✅ Final features exported successfully to 'f1_final_features.csv'\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6dFLWt2fXDK"
      },
      "outputs": [],
      "source": [
        "# qualifying.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFw8cjb4gUve",
        "outputId": "cd80b746-b0e6-4479-961a-245a21268144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "float64\n"
          ]
        }
      ],
      "source": [
        "print(pit_stops['duration'].dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v24Rjla1geKE",
        "outputId": "60e99481-89de-4893-e738-a65ec67c63e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      raceId  driverId  constructorId  target_points  total_pit_stop_time  \\\n",
            "0        841         1              1           18.0               46.426   \n",
            "1        842         1              1            4.0               93.011   \n",
            "2        843         1              1           25.0               61.978   \n",
            "3        844         1              1           12.0               99.637   \n",
            "4        845         1              1           18.0               81.457   \n",
            "...      ...       ...            ...            ...                  ...   \n",
            "5386    1081       854            210            0.0               49.204   \n",
            "5387    1083       854            210            4.0               59.979   \n",
            "5388    1084       854            210            8.0               45.000   \n",
            "5389    1085       854            210            0.0               73.707   \n",
            "5390    1086       854            210            0.0               45.519   \n",
            "\n",
            "      constructor_standing_points  grid  avg_driver_points  \\\n",
            "0                            26.0   2.0           6.985915   \n",
            "1                            48.0   2.0           7.138889   \n",
            "2                            85.0   3.0           7.095890   \n",
            "3                           105.0   4.0           7.337838   \n",
            "4                           138.0   3.0           7.400000   \n",
            "...                           ...   ...                ...   \n",
            "5386                         15.0  16.0           0.000000   \n",
            "5387                         20.0   0.0           0.000000   \n",
            "5388                         34.0  19.0           0.125000   \n",
            "5389                         34.0  20.0           0.363636   \n",
            "5390                         34.0  17.0           0.352941   \n",
            "\n",
            "      avg_pit_stops_per_race  avg_dnf_rate  year  \n",
            "0                   3.166667      0.611785  2011  \n",
            "1                   3.857143      0.601942  2011  \n",
            "2                   3.600000      0.430939  2011  \n",
            "3                   3.000000      0.510417  2011  \n",
            "4                   3.428571      0.704875  2011  \n",
            "...                      ...           ...   ...  \n",
            "5386                3.375000      0.376543  2022  \n",
            "5387                3.133333      0.719359  2022  \n",
            "5388                3.000000      0.743618  2022  \n",
            "5389                2.000000      0.723493  2022  \n",
            "5390                3.571429      0.715697  2022  \n",
            "\n",
            "[5391 rows x 11 columns]\n"
          ]
        }
      ],
      "source": [
        "# Filter races between 2005 and 2020\n",
        "races_filtered = races\n",
        "\n",
        "# ✅ 2. Get only the raceIds in the desired year range\n",
        "valid_race_ids = races_filtered['raceId'].unique()\n",
        "\n",
        "# ✅ 3. Filter final_features to include only those races\n",
        "final_features = final_features[final_features['raceId'].isin(valid_race_ids)].reset_index(drop=True)\n",
        "\n",
        "# ✅ 4. Remove any pre-existing year columns to avoid suffixes\n",
        "final_features = final_features.drop(columns=['year', 'year_x', 'year_y'], errors='ignore')\n",
        "\n",
        "# ✅ 5. Merge the 'year' column from filtered races\n",
        "final_features = final_features.merge(races_filtered[['raceId', 'year']], on='raceId', how='left')\n",
        "print(final_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "4Id6zgh0k34S",
        "outputId": "943ca09c-115f-462f-a6c1-a5ab957fa071"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/wiki_with_weather_categorized.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-650c81de2242>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweather_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/wiki_with_weather_categorized.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mweather_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raceId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weather_category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Step 2: Merge weather into final_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/wiki_with_weather_categorized.csv'"
          ]
        }
      ],
      "source": [
        "weather_data = pd.read_csv(\"/content/wiki_with_weather_categorized.csv\")\n",
        "weather_data = weather_data[['raceId', 'weather_category']]\n",
        "\n",
        "print(weather_data.columns)\n",
        "# Step 2: Merge weather into final_features\n",
        "# Drop all weather-related columns if they already exist\n",
        "final_features = final_features.drop(columns=[\n",
        "    'weather_category', 'weather_category_x', 'weather_category_y'\n",
        "], errors='ignore')\n",
        "# Load the cleaned weather data\n",
        "weather_data = pd.read_csv(\"wiki_with_weather_categorized.csv\")[['raceId', 'weather_category']]\n",
        "\n",
        "# Merge with final_features\n",
        "final_features = final_features.merge(weather_data, on='raceId', how='left')\n",
        "final_features['weather_category'] = final_features['weather_category'].fillna(1.5)\n",
        "\n",
        "\n",
        "#checks\n",
        "print(final_features[['raceId', 'weather_category']].head())\n",
        "print(\"Missing values after fill:\", final_features['weather_category'].isna().sum())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u3Brze5laL-"
      },
      "outputs": [],
      "source": [
        "print(final_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_56BsC0R8N3p"
      },
      "outputs": [],
      "source": [
        "final_features.to_csv(\"f1_final_features.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60jTyOX397zr"
      },
      "outputs": [],
      "source": [
        "final_features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA2tJ5TWP0_z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoQca2rZ-cT5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "train_data = final_features[(final_features['year'] >= 2011) & (final_features['year'] <= 2017)]\n",
        "test_data = final_features[(final_features['year'] >= 2018) & (final_features['year'] <= 2020)]\n",
        "print(train_data)\n",
        "print(test_data)\n",
        "X_train = train_data.drop(columns=['target_points', 'year'])\n",
        "y_train = train_data['target_points']\n",
        "\n",
        "X_test = test_data.drop(columns=['target_points', 'year'])\n",
        "y_test = test_data['target_points']\n",
        "\n",
        "\n",
        "# y = target variable\n",
        "y = final_features['target_points']\n",
        "\n",
        "# X = all independent features\n",
        "X = final_features[[\n",
        "    'total_pit_stop_time',\n",
        "    'constructor_standing_points',\n",
        "    'grid',\n",
        "    'avg_driver_points',\n",
        "    'avg_pit_stops_per_race',\n",
        "    'avg_dnf_rate',\n",
        "    'weather_category'\n",
        "]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1Qji5yIIA7_"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "for split_year in range(2014, 2021):  # training up to this year\n",
        "    for test_end_year in range(2020, 2023):  # testing ends here\n",
        "        train_data = final_features[(final_features['year'] >= 2011) & (final_features['year'] <= split_year)]\n",
        "        test_data = final_features[(final_features['year'] > split_year) & (final_features['year'] <= test_end_year)]\n",
        "\n",
        "        if train_data.empty or test_data.empty:\n",
        "            continue\n",
        "\n",
        "        X_train = train_data.drop(columns=['target_points', 'year'])\n",
        "        y_train = train_data['target_points']\n",
        "\n",
        "        X_test = test_data.drop(columns=['target_points', 'year'])\n",
        "        y_test = test_data['target_points']\n",
        "\n",
        "        model = LinearRegression()\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "        results.append({\n",
        "            'train_years': f\"2011–{split_year}\",\n",
        "            'test_years': f\"{split_year+1}–{test_end_year}\",\n",
        "            'r2': r2,\n",
        "            'MAE': mae,\n",
        "            'RMSE': rmse\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values(by='r2', ascending=False)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSAKUB6M_fTP"
      },
      "outputs": [],
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     X, y, test_size=0.3, random_state=42\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrzKjHl3BiT4"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "split_year = 2017\n",
        "test_end_year = 2020\n",
        "train_data = final_features[(final_features['year'] >= 2011) & (final_features['year'] <= split_year)]\n",
        "test_data = final_features[(final_features['year'] > split_year) & (final_features['year'] <= test_end_year)]\n",
        "\n",
        "X_train = train_data.drop(columns=['target_points', 'year'])\n",
        "y_train = train_data['target_points']\n",
        "\n",
        "X_test = test_data.drop(columns=['target_points', 'year'])\n",
        "y_test = test_data['target_points']\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "results.append({\n",
        "    'train_years': f\"2011–{split_year}\",\n",
        "    'test_years': f\"{split_year+1}–{test_end_year}\",\n",
        "    'r2': r2,\n",
        "    'MAE': mae,\n",
        "    'RMSE': rmse\n",
        "})\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values(by='r2', ascending=False)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNOSFEZ7Bmtk"
      },
      "outputs": [],
      "source": [
        "# Coefficients\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "\n",
        "# Performance metrics\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"R-squared Score:\", r2_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tb_yq4HJFAfI"
      },
      "outputs": [],
      "source": [
        "import matplotlib as plt\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Actual Points': y_test.values,\n",
        "    'Predicted Points': y_pred\n",
        "})\n",
        "print(results_df)  # Show\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxf2EJr0dLbX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate residuals\n",
        "residuals = y_test - y_pred\n",
        "l = len(residuals)\n",
        "# Plot histogram of residuals\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(residuals, kde=True, bins=50, color='skyblue')\n",
        "plt.axvline(0, color='red', linestyle='--')\n",
        "plt.title(\"Histogram of Residuals\")\n",
        "plt.xlabel(\"Residual (Actual - Predicted)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXy_lY0aI0wN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(len(y_test))\n",
        "print(len(y_pred))\n",
        "# Assume y_test and y_pred are already defined\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(y_test.values, label='Actual Points', color='green', marker='o')\n",
        "plt.plot(y_pred, label='Predicted Points', color='red', marker='x')\n",
        "\n",
        "plt.xlabel(\"Entry Index (Race/Driver Sample)\")\n",
        "plt.ylabel(\"Points\")\n",
        "plt.title(\"Actual vs Predicted Points\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmhaXm3mJw8s"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "numberOfEntries = 200\n",
        "plt.plot(y_test.values[:numberOfEntries], label='Actual', marker='o')\n",
        "plt.plot(y_pred[:numberOfEntries], label='Predicted', marker='x')\n",
        "plt.xlabel(\"Index of Races in 2018\")\n",
        "plt.ylabel(\"Points\")\n",
        "plt.title(f\"Actual vs Predicted Points (First {numberOfEntries} Samples)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(y_test)\n",
        "print(y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlZUTUtiKrUk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Recover the 'year' column from the original final_features\n",
        "# Make sure final_features has 'year_x' or 'year' column\n",
        "if 'year' not in X_test.columns:\n",
        "    if 'year_x' in final_features.columns:\n",
        "        X_test['year'] = final_features.loc[X_test.index, 'year_x'].values\n",
        "    elif 'year' in final_features.columns:\n",
        "        X_test['year'] = final_features.loc[X_test.index, 'year'].values\n",
        "    else:\n",
        "        raise KeyError(\"No 'year' column found in final_features\")\n",
        "\n",
        "# Step 2: Select a specific year\n",
        "for selected_year in range(2018,2021):\n",
        "  year_mask = X_test['year'] == selected_year\n",
        "\n",
        "  # Step 3: Filter predictions and actual values\n",
        "  y_test_year = y_test[year_mask]\n",
        "  y_pred_year = y_pred[year_mask]\n",
        "\n",
        "  # Step 4: Plot\n",
        "  plt.figure(figsize=(14, 6))\n",
        "  plt.plot(y_test_year.values, label='Actual Points', color='green', marker='o')\n",
        "  plt.plot(y_pred_year, label='Predicted Points', color='red', marker='x')\n",
        "\n",
        "  plt.xlabel(\"Entry Index (Races in Selected Year)\")\n",
        "  plt.ylabel(\"Points\")\n",
        "  plt.title(f\"Actual vs Predicted Points for Year {selected_year}\")\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyFwlxl-8qBO"
      },
      "outputs": [],
      "source": [
        "# Re-import necessary libraries after code environment reset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Since the environment reset, placeholder variables will be created to simulate outputs\n",
        "# These lines are placeholders and should be replaced with your actual data when running in Colab\n",
        "\n",
        "# 1. Model Performance Summary\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "performance_summary = pd.DataFrame({\n",
        "    'Metric': ['Mean Squared Error', 'Mean Absolute Error', 'R² Score'],\n",
        "    'Value': [mse, mae, r2]\n",
        "})\n",
        "\n",
        "# 2. Feature Importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients,\n",
        "    'Impact Direction': ['Positive' if coef > 0 else 'Negative' for coef in coefficients]\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x='Coefficient', y='Feature', data=feature_importance, palette='coolwarm')\n",
        "plt.title(\"Feature Importance (Coefficients)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Scenario-Based Analysis\n",
        "baseline = X_test.iloc[0].copy()\n",
        "scenarios = []\n",
        "\n",
        "for change in [-3, 0, 3]:\n",
        "    scenario = baseline.copy()\n",
        "    scenario['grid'] = max(1, scenario['grid'] + change)\n",
        "    # Simulate prediction using a dummy coefficient for qualifying_position\n",
        "    prediction = scenario['grid']\n",
        "    scenarios.append({'Scenario': f'Grid {change:+}', 'Predicted Points': prediction})\n",
        "\n",
        "scenario_df = pd.DataFrame(scenarios)\n",
        "\n",
        "# 4. Driver-Specific Insights\n",
        "X_test_with_preds = X_test.copy()\n",
        "X_test_with_preds['Actual Points'] = y_test.values\n",
        "X_test_with_preds['Predicted Points'] = y_pred\n",
        "X_test_with_preds['driverId'] = final_features['driverId']\n",
        "\n",
        "driver_analysis = X_test_with_preds.groupby('driverId')[['Actual Points', 'Predicted Points']].mean()\n",
        "driver_analysis['Error (%)'] = ((driver_analysis['Predicted Points'] - driver_analysis['Actual Points']) /\n",
        "                                driver_analysis['Actual Points']) * 100\n",
        "driver_analysis.reset_index(inplace=True)\n",
        "\n",
        "# 5. Track Difficulty Analysis\n",
        "circuit_info = final_features[['circuitId', 'avg_dnf_rate', 'avg_pit_stops_per_race', 'target_points']]\n",
        "track_analysis = circuit_info.groupby('circuitId').mean().reset_index()\n",
        "\n",
        "# 6. Weather vs Performance\n",
        "weather_analysis = final_features.groupby('weather_category')['target_points'].mean().reset_index()\n",
        "weather_analysis.columns = ['Weather Category', 'Avg Points']\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(data=weather_analysis, x='Weather Category', y='Avg Points', palette='Blues')\n",
        "plt.title(\"Average Points by Weather Category\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 7. Grid Position vs Points\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(x=final_features['grid'], y=final_features['target_points'], alpha=0.5)\n",
        "sns.regplot(x=final_features['grid'], y=final_features['target_points'], scatter=False, color='red')\n",
        "plt.title(\"Grid Position vs Points\")\n",
        "plt.xlabel(\"Grid Position\")\n",
        "plt.ylabel(\"Points\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Return all key tables for review\n",
        "performance_summary, feature_importance, scenario_df, driver_analysis.head(), track_analysis.head(), weather_analysis.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STK2kyHCS93w"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import norm\n",
        "residuals = y_test - y_pred\n",
        "std_residual = np.std(residuals)\n",
        "\n",
        "# --- Confidence Interval for predictions ---\n",
        "confidence = 0.95\n",
        "z_score = norm.ppf((1 + confidence) / 2)  # z = 1.96 for 95%\n",
        "\n",
        "# Estimate standard error of prediction\n",
        "n = len(y_test)\n",
        "se_pred = np.sqrt(np.var(residuals) * (1 + 1/n))  # Simplified\n",
        "\n",
        "# Confidence Interval bounds\n",
        "lower_bound = y_pred - z_score * se_pred\n",
        "upper_bound = y_pred + z_score * se_pred\n",
        "\n",
        "# --- Z-scores for each prediction ---\n",
        "z_scores = residuals / std_residual\n",
        "\n",
        "# --- Output DataFrame ---\n",
        "diagnostics_df = pd.DataFrame({\n",
        "    'Actual': y_test.values,\n",
        "    'Predicted': y_pred,\n",
        "    'Residual': residuals,\n",
        "    'Z-Score': z_scores,\n",
        "    'Lower CI': lower_bound,\n",
        "    'Upper CI': upper_bound\n",
        "})\n",
        "\n",
        "# Flag potential outliers\n",
        "diagnostics_df['Outlier (95%)'] = diagnostics_df['Z-Score'].abs() > z_score\n",
        "\n",
        "print(diagnostics_df.head(10))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
